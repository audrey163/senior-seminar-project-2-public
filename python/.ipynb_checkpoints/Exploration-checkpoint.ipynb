{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631814dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pprint as pp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dynamicalsystems import SimplePendulum\n",
    "from regression import PolynomialLibrary, TrigLibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e467ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SimplePendulum(g=9.8,l=2,mu=0.5,theta0=np.pi/2) #simulate pendulum\n",
    "sp.embed(n=10,mat='RANDN',mu=0,sigma=0.0) #embed the pendulum in a higer diminsional space with noise\n",
    "print(sp.Z)\n",
    "print(sp.Z.shape)\n",
    "sp.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6c783-69ec-4b67-9a55-7249234fc075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeatedly reduce the size\n",
    "class Autoencoder_Linear(nn.Module):\n",
    "    self.dZ = []\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(10, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2) # -> N, 3\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2,4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4,8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x,dX=None):\n",
    "        encoded = self.encoder(x)\n",
    "        if dx is not None:\n",
    "            self.dZ.append()\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "# Input [-1, +1] -> use nn.Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109e17c-8ebe-4218-8e3c-86af490fd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder_Linear()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6392fc-ba56-494e-bff6-fc1b2f31b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(torch.Tensor(sp.Z[:,0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae1afe5-4af5-4b41-892b-abcc3a2e52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52701ef4-a82c-41c8-b1af-f497f03472be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to training loop video\n",
    "num_epochs = 1000\n",
    "outputs = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # img = img.reshape(-1, 28*28) # -> use for Autoencoder_Linear\n",
    "    X = torch.Tensor(sp.Z.T)\n",
    "    recon = model(X)\n",
    "    loss = criterion(recon, X)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')\n",
    "    outputs.append((epoch, X, recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88039b-1d37-4fc9-a299-333411072276",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.encoder(torch.Tensor(sp.Z.T)).detach().numpy()[:,0],model.encoder(torch.Tensor(sp.Z.T)).detach().numpy()[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ff727-ddc8-41c0-905c-843064d67b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor(sp.Z.T)\n",
    "recon = model(X)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f828180-b414-4250-8288-275c31d48fca",
   "metadata": {},
   "source": [
    "loss = criterion(recon, X)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4cbc4d-d276-482c-a4a1-09cec2c0b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINDy(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, \n",
    "        X_dot=None, \n",
    "        libs=None, \n",
    "        feature_names=None\n",
    "    ):\n",
    "        super(SINDy, self).__init__()\n",
    "\n",
    "        n,m = X.size()\n",
    "        if feature_names == None:\n",
    "            feature_names = [f'x{i+1}' for i in range(m)]\n",
    "\n",
    "        self.X = X\n",
    "        self.X_dot = X_dot\n",
    "        self.feature_names = feature_names\n",
    "        self.num_features  = m\n",
    "        self.num_snapshots = n\n",
    "\n",
    "        self.candidate_terms = [ lambda x: torch.ones(self.num_snapshots) ]\n",
    "        self.candidate_names = ['1']\n",
    "        for lib in libs:\n",
    "            lib_candidates = lib.get_candidates(self.num_features, feature_names)\n",
    "            for term, name in lib_candidates:\n",
    "                self.candidate_terms.append(term)\n",
    "                self.candidate_names.append(name)\n",
    "\n",
    "        self.SINDy_forward = nn.Linear(\n",
    "            len(self.candidate_terms), \n",
    "            self.num_features, \n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "    def library(self):\n",
    "        print('library candidate terms:')\n",
    "        return self.candidate_names\n",
    "    \n",
    "    def model_parameters(self):\n",
    "        params = list(self.parameters())[0]\n",
    "        return params\n",
    "    \n",
    "    def theta(self,X):\n",
    "        return torch.stack(tuple(f(X) for f in self.candidate_terms), axis=1)\n",
    "\n",
    "    def forward(self):\n",
    "        theta_X = self.theta(self.X)\n",
    "        \n",
    "        # X_dot_predict = f(X) = Θ(X)Ξ = Θ(X)[ ξ1, ξ2, ..., ξn ]\n",
    "        X_dot_predict = self.SINDy_forward(theta_X)\n",
    "        return X_dot_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd42d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# t = torch.linspace(0,2,100)\n",
    "\n",
    "# x = 10 * torch.exp(- 0.5 * t)\n",
    "# y = -2 * torch.exp(3 * t)\n",
    "\n",
    "# x_dot = - 0.5 * x\n",
    "# y_dot = 3 * y\n",
    "\n",
    "# X = torch.stack((x,y), dim=-1)\n",
    "# X_dot = torch.stack((x_dot,y_dot), dim=-1)\n",
    "# X[:5]\n",
    "\n",
    "# X_dot[:5,:]\n",
    "# ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# libs  = [\n",
    "#   PolynomialLibrary(max_degree=1),\n",
    "#   TrigLibrary()\n",
    "# ]\n",
    "\n",
    "# sindy = SINDy(\n",
    "#     X, \n",
    "#     X_dot=X_dot, \n",
    "#     libs=libs,\n",
    "#     feature_names=['x', 'y']\n",
    "# )\n",
    "\n",
    "# print(sindy.library())\n",
    "# print(sindy.model_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94658ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_2 = lambda X: torch.linalg.norm(X)\n",
    "\n",
    "# loss_fn = lambda X, X_pred: norm_2(X - X_pred)\n",
    "# optimizer = torch.optim.Adam(sindy.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 10000\n",
    "\n",
    "# for t in range(epochs):\n",
    "    \n",
    "#     X_dot_pred = sindy()\n",
    "#     loss = loss_fn(X_dot, X_dot_pred)\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     if t % 1000 == 0:\n",
    "#         print(loss)\n",
    "\n",
    "# print(sindy.library())\n",
    "# sindy.model_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bcd1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = torch.tensor([\n",
    "#     [1,2],\n",
    "#     [3,4]\n",
    "# ])\n",
    "# x2 = x1 * 10\n",
    "# [*x for x in [x1,x2]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
