{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "631814dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pprint as pp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dynamicalsystems import SimplePendulum\n",
    "from regression import PolynomialLibrary, TrigLibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fdee97b-ffc5-471c-aa96-29ff9ec4f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINDy(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, \n",
    "        X_dot=None, \n",
    "        libs=None, \n",
    "        feature_names=None\n",
    "    ):\n",
    "        super(SINDy, self).__init__()\n",
    "\n",
    "        n,m = X.size()\n",
    "        if feature_names == None:\n",
    "            feature_names = [f'x{i+1}' for i in range(m)]\n",
    "\n",
    "        self.X = X\n",
    "        self.X_dot = X_dot\n",
    "        self.feature_names = feature_names\n",
    "        self.num_features  = m\n",
    "        self.num_snapshots = n\n",
    "\n",
    "        self.candidate_terms = [ lambda x: torch.ones(self.num_snapshots) ]\n",
    "        self.candidate_names = ['1']\n",
    "        for lib in libs:\n",
    "            lib_candidates = lib.get_candidates(self.num_features, feature_names)\n",
    "            for term, name in lib_candidates:\n",
    "                self.candidate_terms.append(term)\n",
    "                self.candidate_names.append(name)\n",
    "\n",
    "        self.SINDy_forward = nn.Linear(\n",
    "            len(self.candidate_terms), \n",
    "            self.num_features, \n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "    def library(self):\n",
    "        print('library candidate terms:')\n",
    "        return self.candidate_names\n",
    "    \n",
    "    def model_parameters(self):\n",
    "        params = list(self.parameters())[0]\n",
    "        return params\n",
    "    \n",
    "    def theta(self,X):\n",
    "        return torch.stack(tuple(f(X) for f in self.candidate_terms), axis=1)\n",
    "\n",
    "    def forward(self):\n",
    "        theta_X = self.theta(self.X)\n",
    "        \n",
    "        # X_dot_predict = f(X) = Θ(X)Ξ = Θ(X)[ ξ1, ξ2, ..., ξn ]\n",
    "        X_dot_predict = self.SINDy_forward(theta_X)\n",
    "        return X_dot_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96b568d3-c708-4898-aecf-6f1a46532859",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SimplePendulum(g=9.8,l=2,mu=0.5,theta0=np.pi/2) # Simple Pendulum simulated in state space\n",
    "\n",
    "sp.embed(n=10,mat='RANDN',mu=0,sigma=0.0) #embed the pendulum in a higer diminsional space with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32e467ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U', 'dU', 'X', 'dX']\n"
     ]
    }
   ],
   "source": [
    "data = sp.to_torch() #get the torch tensors\n",
    "\n",
    "print(list(data)) # U and dU are the state space representation theta while X and dX are embeded they are our transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18bd7b47-a4be-4273-9aa3-29abd8bfb7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5078, -0.7740,  1.4034,  2.2963, -3.2695, -0.2759,  0.7697, -2.9102,\n",
      "          1.1880,  0.2308],\n",
      "        [-0.3477,  0.1712,  3.9977, -1.6840, -2.0394, -0.6260,  1.1466, -1.0190,\n",
      "          6.1898, -0.4167],\n",
      "        [-0.0800,  0.3261, -3.0418, -0.2983,  2.9488,  0.5071, -1.0734,  2.1718,\n",
      "         -4.1710,  0.1108]])\n",
      "tensor([[-0.5653,  0.1233,  8.6407, -2.7861, -5.1632, -1.3697,  2.5870, -2.9573,\n",
      "         13.0877, -0.7892],\n",
      "        [-0.5059,  1.1159, -6.1616, -2.1805,  7.3672,  1.0577, -2.3747,  5.7925,\n",
      "         -7.9111,  0.0186],\n",
      "        [ 0.7371, -0.7328, -3.3636,  3.4550, -0.0865,  0.4871, -0.7056, -0.9443,\n",
      "         -5.9033,  0.6168]])\n",
      "tensor([[ 1.5708,  0.0000],\n",
      "        [-0.2258, -2.3814],\n",
      "        [-0.7309,  1.3546]])\n",
      "tensor([[ 0.0000, -4.9000],\n",
      "        [-2.3814,  2.2876],\n",
      "        [ 1.3546,  2.5938]])\n"
     ]
    }
   ],
   "source": [
    "#data['X'] is the X data\n",
    "#data['dX'] is the dX computed from f(t,x)\n",
    "#data['U'] and data['dU'] are the ground truth of the dynamical system in [theta, thetadot] state space\n",
    "print(data['X'][0:300:100,:]) \n",
    "print(data['dX'][0:300:100,:])\n",
    "print(data['U'][0:300:100,:])\n",
    "print(data['dU'][0:300:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94717f2c-5c73-48e2-b2ba-8dc3729eba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "libs = [ PolynomialLibrary(max_degree=1), TrigLibrary() ]\n",
    "\n",
    "sindy = SINDy(\n",
    "    data['U'],\n",
    "    X_dot = data['dU'],\n",
    "     libs=libs,\n",
    "     feature_names=['x', 'y']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cf6c783-69ec-4b67-9a55-7249234fc075",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.libs = [ PolynomialLibrary(max_degree=1), TrigLibrary() ]\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(10, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2) # -> N, 3\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2,4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4,8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def get_dZ(self,x,dx):\n",
    "        J = torch.autograd.functional.jacobian(self.encoder, x)\n",
    "        return torch.matmul(J.T,dx)\n",
    " \n",
    "    # def get_dX(self,z,dz):\n",
    "    #     J = torch.autograd.functional.jacobian(self.decoder, z)\n",
    "    #     return torch.matmul(J.T,dz)\n",
    "\n",
    "    def loss(self,x,dx):\n",
    "        z = self.encoder(x)\n",
    "        dz = self.get_dZ(x,dx)\n",
    "        x_pred = self.decoder(z)\n",
    "        #dx_pred = self.get_dX(z,dz)\n",
    "        return torch.norm(x-x_pred)#+torch.norm(dx_pred-dx)\n",
    "# Input [-1, +1] -> use nn.Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca16ec-ef20-42fd-9028-69205a1d6049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6109e17c-8ebe-4218-8e3c-86af490fd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca6392fc-ba56-494e-bff6-fc1b2f31b42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0109,  0.1931,  0.0431,  ...,  0.5645, -0.5122, -0.0158],\n",
       "        [ 0.0109,  0.1931,  0.0432,  ...,  0.5645, -0.5120, -0.0158],\n",
       "        [ 0.0108,  0.1931,  0.0432,  ...,  0.5644, -0.5119, -0.0159],\n",
       "        ...,\n",
       "        [ 0.0097,  0.1928,  0.0434,  ...,  0.5639, -0.5096, -0.0164],\n",
       "        [ 0.0097,  0.1928,  0.0434,  ...,  0.5639, -0.5096, -0.0164],\n",
       "        [ 0.0097,  0.1928,  0.0434,  ...,  0.5639, -0.5096, -0.0164]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(data['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52701ef4-a82c-41c8-b1af-f497f03472be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to training loop video\n",
    "num_epochs = 100\n",
    "#outputs = []\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # #recon = model(data['X'])\n",
    "    #     z = self.encoder(x)\n",
    "    #     #dz = self.get_dZ(x,dx)\n",
    "    #     x_pred = self.decoder(z)\n",
    "    #     #dx_pred = self.get_dX(z,dz)\n",
    "    #     return torch.norm(x-x_pred)#+torch.norm(dx_pred-dx)  \n",
    "    loss = model.loss(data['X'],data['dX'])\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #outputs.append((epoch, data['X'], recon))\n",
    "    #print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc60278b-8e43-46ac-833d-a7a9f6d31ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'log loss')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.log(np.array(losses)))\n",
    "plt.title(\"log loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e88039b-1d37-4fc9-a299-333411072276",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['dX'][0:20,:]\n",
    "dx = data['dX'][0:20,:]\n",
    "\n",
    "z = model.encoder(x)\n",
    "dz = model.get_dZ(x,dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9f9c53e-b051-424c-8412-c01e2a451b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6713,  4.4534],\n",
       "        [-3.6648,  4.4461],\n",
       "        [-3.6584,  4.4388],\n",
       "        [-3.6520,  4.4316],\n",
       "        [-3.6457,  4.4244],\n",
       "        [-3.6394,  4.4172],\n",
       "        [-3.6330,  4.4100],\n",
       "        [-3.6266,  4.4028],\n",
       "        [-3.6202,  4.3955],\n",
       "        [-3.6138,  4.3882],\n",
       "        [-3.6073,  4.3808],\n",
       "        [-3.6007,  4.3733],\n",
       "        [-3.5939,  4.3656],\n",
       "        [-3.5866,  4.3573],\n",
       "        [-3.5790,  4.3488],\n",
       "        [-3.5713,  4.3400],\n",
       "        [-3.5633,  4.3309],\n",
       "        [-3.5550,  4.3216],\n",
       "        [-3.5465,  4.3118],\n",
       "        [-3.5375,  4.3016]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a6dd857-09b5-4166-85e7-56d158fa001d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a10a566-2d4d-4e72-87dd-81042769dad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20, 2, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbbc54df-87f8-4be7-b4d8-6dc8c85e295e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_dZ() missing 1 required positional argument: 'dx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dZ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dZ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_dZ() missing 1 required positional argument: 'dx'"
     ]
    }
   ],
   "source": [
    "dZ = model.get_dZ(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ad448-ecf4-4fa9-b203-fc40f70193fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dZ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a92bf-b3db-4867-b06b-935a686c7ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_z = Z.detach().numpy()\n",
    "plt.plot(_z[:,0],_z[:,1])\n",
    "plt.title(\"Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd281e7f-3eb1-40c8-9f3d-25cd98aacba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['X'][0,:]\n",
    "dx = data['dX'][0,:]\n",
    "z = model.encoder(x).detach().numpy().reshape(-1,1)\n",
    "\n",
    "J = torch.autograd.functional.jacobian(model.encoder, dx).detach().numpy()\n",
    "\n",
    "dz = np.dot(J.T,z)\n",
    "\n",
    "print(dz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064836c4-5c4d-4d3b-889a-affa9b381ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['X'][0,:]\n",
    "dx = data['dX'][0,:]\n",
    "z = model.encoder(x)\n",
    "\n",
    "J = torch.autograd.functional.jacobian(model.encoder, dx)\n",
    "\n",
    "print(z.shape)\n",
    "print(J.shape)\n",
    "dz = torch.matmul(J.T,z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ff727-ddc8-41c0-905c-843064d67b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor(sp.Z.T)\n",
    "recon = model(X)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f828180-b414-4250-8288-275c31d48fca",
   "metadata": {},
   "source": [
    "loss = criterion(recon, X)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4cbc4d-d276-482c-a4a1-09cec2c0b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINDy(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, \n",
    "        X_dot=None, \n",
    "        libs=None, \n",
    "        feature_names=None\n",
    "    ):\n",
    "        super(SINDy, self).__init__()\n",
    "\n",
    "        n,m = X.size()\n",
    "        if feature_names == None:\n",
    "            feature_names = [f'x{i+1}' for i in range(m)]\n",
    "\n",
    "        self.X = X\n",
    "        self.X_dot = X_dot\n",
    "        self.feature_names = feature_names\n",
    "        self.num_features  = m\n",
    "        self.num_snapshots = n\n",
    "\n",
    "        self.candidate_terms = [ lambda x: torch.ones(self.num_snapshots) ]\n",
    "        self.candidate_names = ['1']\n",
    "        for lib in libs:\n",
    "            lib_candidates = lib.get_candidates(self.num_features, feature_names)\n",
    "            for term, name in lib_candidates:\n",
    "                self.candidate_terms.append(term)\n",
    "                self.candidate_names.append(name)\n",
    "\n",
    "        self.SINDy_forward = nn.Linear(\n",
    "            len(self.candidate_terms), \n",
    "            self.num_features, \n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "    def library(self):\n",
    "        print('library candidate terms:')\n",
    "        return self.candidate_names\n",
    "    \n",
    "    def model_parameters(self):\n",
    "        params = list(self.parameters())[0]\n",
    "        return params\n",
    "    \n",
    "    def theta(self,X):\n",
    "        return torch.stack(tuple(f(X) for f in self.candidate_terms), axis=1)\n",
    "\n",
    "    def forward(self):\n",
    "        theta_X = self.theta(self.X)\n",
    "        \n",
    "        # X_dot_predict = f(X) = Θ(X)Ξ = Θ(X)[ ξ1, ξ2, ..., ξn ]\n",
    "        X_dot_predict = self.SINDy_forward(theta_X)\n",
    "        return X_dot_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd42d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# t = torch.linspace(0,2,100)\n",
    "\n",
    "# x = 10 * torch.exp(- 0.5 * t)\n",
    "# y = -2 * torch.exp(3 * t)\n",
    "\n",
    "# x_dot = - 0.5 * x\n",
    "# y_dot = 3 * y\n",
    "\n",
    "# X = torch.stack((x,y), dim=-1)\n",
    "# X_dot = torch.stack((x_dot,y_dot), dim=-1)\n",
    "# X[:5]\n",
    "\n",
    "# X_dot[:5,:]\n",
    "# ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# libs  = [\n",
    "#   PolynomialLibrary(max_degree=1),\n",
    "#   TrigLibrary()\n",
    "# ]\n",
    "\n",
    "# sindy = SINDy(\n",
    "#     X, \n",
    "#     X_dot=X_dot, \n",
    "#     libs=libs,\n",
    "#     feature_names=['x', 'y']\n",
    "# )\n",
    "\n",
    "# print(sindy.library())\n",
    "# print(sindy.model_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94658ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_2 = lambda X: torch.linalg.norm(X)\n",
    "\n",
    "# loss_fn = lambda X, X_pred: norm_2(X - X_pred)\n",
    "# optimizer = torch.optim.Adam(sindy.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 10000\n",
    "\n",
    "# for t in range(epochs):\n",
    "    \n",
    "#     X_dot_pred = sindy()\n",
    "#     loss = loss_fn(X_dot, X_dot_pred)\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     if t % 1000 == 0:\n",
    "#         print(loss)\n",
    "\n",
    "# print(sindy.library())\n",
    "# sindy.model_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bcd1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = torch.tensor([\n",
    "#     [1,2],\n",
    "#     [3,4]\n",
    "# ])\n",
    "# x2 = x1 * 10\n",
    "# [*x for x in [x1,x2]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
