{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "631814dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pprint as pp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "\n",
    "from regression import PolynomialLibrary, TrigLibrary\n",
    "import sindy_helper\n",
    "from dynamicalsystems import TrainDataset\n",
    "from fullSINDyAutoencoder import FullSINDyAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a26ae1d6-c138-492d-81ca-2e4f246c67bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still debuging FullSINDyAutoencoder.get_dX I set the reg['dX'] = 0 in the loss args\n"
     ]
    }
   ],
   "source": [
    "print(\"Still debuging FullSINDyAutoencoder.get_dX I set the reg['dX'] = 0 in the loss args\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520846fb-2369-4b4a-9365-b9992b5328d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_pers = {\n",
    "    'learn_rate' : 1e-3,\n",
    "    'batch_size' : 64,\n",
    "    'num_epochs' : 1000,\n",
    "    'num_features' : 2,\n",
    "    'loss_reg' : {\n",
    "        'X' : 1,\n",
    "        'SINDy' : 1,\n",
    "        'dX' : 0, \n",
    "        'Xi' : 1\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset = TrainDataset()\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=hyper_pers['batch_size'], shuffle=True, num_workers=2)\n",
    "dataiter = iter(dataloader)\n",
    "\n",
    "model = FullSINDyAutoencoder(hyper_pers['batch_size'], hyper_pers['num_features'])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=hyper_pers['learn_rate'])\n",
    "\n",
    "total_samples = len(dataset)\n",
    "n_iter = math.ceil(total_samples / hyper_pers['batch_size'])\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3633406c-3cfb-40b5-87d5-342814977382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/python/fullSINDyAutoencoder.py:55: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  return torch.matmul(J.T,dx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.960750579833984\n",
      "Epoch 1\n",
      "19.104663848876953\n",
      "Epoch 2\n",
      "14.993900299072266\n",
      "Epoch 3\n",
      "15.967855453491211\n",
      "Epoch 4\n",
      "18.844053268432617\n",
      "Epoch 5\n",
      "12.529773712158203\n",
      "Epoch 6\n",
      "13.94466781616211\n",
      "Epoch 7\n",
      "13.405719757080078\n",
      "Epoch 8\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(hyper_pers['num_epochs']):\n",
    "    print(\"Epoch \" + str(epoch))\n",
    "    l = []\n",
    "    for i, (X, dX) in enumerate(dataloader):\n",
    "        if X.shape[0] == hyper_pers['batch_size']:\n",
    "            res = model.forward(X,dX)\n",
    "            loss = model.loss(args=res,reg=hyper_pers['loss_reg'])   \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            l.append(loss.item())\n",
    "    losses.append(np.mean(np.array(l)))\n",
    "    print(loss.item())\n",
    "    \n",
    "plt.plot(np.log(np.array(losses)))\n",
    "plt.title(\"log loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
